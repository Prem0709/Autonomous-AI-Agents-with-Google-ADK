{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Day AI Agents Intensive: Assignment 1\n",
    "## Introduction to AI Agents and Multi-Agent Architectures\n",
    "\n",
    "---\n",
    "\n",
    "**Course Overview**\n",
    "\n",
    "This assignment combines theoretical understanding with practical implementation of AI agents using Google's Agent Development Kit (ADK). You'll learn:\n",
    "\n",
    "- ‚úÖ Core concepts of AI agents and agentic systems\n",
    "- ‚úÖ Building single agents with tools\n",
    "- ‚úÖ Designing multi-agent architectures\n",
    "- ‚úÖ Implementing workflow patterns (Sequential, Parallel, Loop)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: Theoretical Foundation\n",
    "\n",
    "### 1.1 From Predictive AI to Autonomous Agents\n",
    "\n",
    "Artificial intelligence is undergoing a paradigm shift. Traditional AI models excel at passive, discrete tasks like answering questions or generating images, but they require constant human direction. We're now moving toward **AI agents** - complete applications capable of autonomous problem-solving and task execution.\n",
    "\n",
    "**Key Distinction:**\n",
    "- **Traditional AI**: `Prompt ‚Üí LLM ‚Üí Text`\n",
    "- **AI Agent**: `Prompt ‚Üí Agent ‚Üí Think ‚Üí Act ‚Üí Observe ‚Üí Final Answer`\n",
    "\n",
    "### 1.2 What is an AI Agent?\n",
    "\n",
    "An AI agent combines four essential components:\n",
    "\n",
    "1. **The Model (The \"Brain\")**: Core reasoning engine (LM/foundation model) that processes information and makes decisions\n",
    "2. **Tools (The \"Hands\")**: Mechanisms connecting reasoning to the real world (APIs, functions, databases)\n",
    "3. **Orchestration Layer (The \"Nervous System\")**: Governs the operational loop, manages planning, memory, and reasoning strategies\n",
    "4. **Deployment (The \"Body and Legs\")**: Production infrastructure making the agent accessible and reliable\n",
    "\n",
    "### 1.3 The Agentic Problem-Solving Process\n",
    "\n",
    "Agents operate on a **five-step cyclical process**:\n",
    "\n",
    "1. **Get the Mission**: Receive a specific, high-level goal\n",
    "2. **Scan the Scene**: Gather context from available resources\n",
    "3. **Think It Through**: Devise a plan using the reasoning model\n",
    "4. **Take Action**: Execute the plan using appropriate tools\n",
    "5. **Observe and Iterate**: Analyze outcomes and repeat until goal is achieved\n",
    "\n",
    "**Example: Customer Support Agent**\n",
    "\n",
    "User asks: \"Where is my order #12345?\"\n",
    "\n",
    "The agent:\n",
    "1. Plans a multi-step strategy (find order ‚Üí track shipment ‚Üí report)\n",
    "2. Calls `find_order(\"12345\")` tool\n",
    "3. Observes: order found with tracking number \"ZYX987\"\n",
    "4. Calls `get_shipping_status(\"ZYX987\")` tool\n",
    "5. Observes: \"Out for Delivery\"\n",
    "6. Generates response: \"Your order #12345 is 'Out for Delivery'!\"\n",
    "\n",
    "### 1.4 Taxonomy of Agentic Systems\n",
    "\n",
    "**Level 0: Core Reasoning System**\n",
    "- LM operates in isolation with pre-trained knowledge\n",
    "- No tools, memory, or real-time data access\n",
    "- Can explain concepts but cannot access current information\n",
    "\n",
    "**Level 1: Connected Problem-Solver**\n",
    "- Connects to external tools (search APIs, databases)\n",
    "- Can retrieve real-time information\n",
    "- Example: Searching for current stock prices or weather\n",
    "\n",
    "**Level 2: Strategic Problem-Solver**\n",
    "- Plans complex, multi-step tasks\n",
    "- Employs context engineering to manage information\n",
    "- Example: Finding coffee shops midway between two locations\n",
    "\n",
    "**Level 3: Collaborative Multi-Agent System**\n",
    "- Team of specialized agents working together\n",
    "- Agents treat other agents as tools\n",
    "- Example: Project manager delegating to research, marketing, and web dev agents\n",
    "\n",
    "**Level 4: Self-Evolving System**\n",
    "- Identifies capability gaps and creates new tools/agents\n",
    "- Dynamically expands its own capabilities\n",
    "- Represents the frontier of autonomous systems\n",
    "\n",
    "### 1.5 Multi-Agent Design Patterns\n",
    "\n",
    "When tasks grow complex, specialized agent teams become more effective than single \"super-agents\":\n",
    "\n",
    "**Coordinator Pattern**: Manager agent routes sub-tasks to specialists\n",
    "\n",
    "**Sequential Pattern**: Linear workflow where output of one agent becomes input for next\n",
    "\n",
    "**Iterative Refinement Pattern**: Generator creates content, critic evaluates, loop continues\n",
    "\n",
    "**Human-in-the-Loop (HITL) Pattern**: Agent pauses for human approval at critical decisions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Practical Implementation\n",
    "\n",
    "### Setup and Configuration\n",
    "\n",
    "We'll use Google's Agent Development Kit (ADK) to build our agents. ADK provides:\n",
    "- Modular framework for agent development\n",
    "- Optimized for Gemini models\n",
    "- Support for Python, Java, and Go\n",
    "- Built-in tools and orchestration capabilities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Section 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-generativeai \n",
    "# !pip install google-adk kaggle nbformat \n",
    "# !pip install jupyter_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Configure Gemini API Key\n",
    "\n",
    "**Instructions:**\n",
    "1. Get your API key from [Google AI Studio](https://aistudio.google.com/app/api-keys)\n",
    "2. In Kaggle: Add-ons ‚Üí Secrets ‚Üí Create `GOOGLE_API_KEY`\n",
    "3. Ensure the checkbox is selected to attach the secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# try:\n",
    "#     GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "#     os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "#     print(\"‚úÖ Gemini API key setup complete.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"üîí Authentication Error: {e}\")\n",
    "#     print(\"Please add 'GOOGLE_API_KEY' to your Kaggle secrets.\")\n",
    "\n",
    "import os\n",
    "\n",
    "# üîë Replace with your actual Gemini API key from Google AI Studio\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"......qCI\"   #YOUR_API_KEY_HERE\n",
    "\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "else:\n",
    "    print(\"‚ùå API key not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Import ADK Components\n",
    "\n",
    "Now, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCP requires Python 3.10 or above. Please upgrade your Python version in order to use it.\n",
      "MCP requires Python 3.10 or above. Please upgrade your Python version in order to use it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "\n",
    "We'll define some helper functions. If you are running this outside the Kaggle environment, you don't need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pawar\\AppData\\Local\\Temp\\ipykernel_9908\\3275386924.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Define helper functions that will be reused throughout the notebook\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from jupyter_server.serverapp import list_running_servers\n",
    "\n",
    "\n",
    "# Gets the proxied URL in the Kaggle Notebooks environment\n",
    "def get_adk_proxy_url():\n",
    "    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n",
    "    ADK_PORT = \"8000\"\n",
    "\n",
    "    servers = list(list_running_servers())\n",
    "    if not servers:\n",
    "        raise Exception(\"No running Jupyter servers found.\")\n",
    "\n",
    "    baseURL = servers[0][\"base_url\"]\n",
    "\n",
    "    try:\n",
    "        path_parts = baseURL.split(\"/\")\n",
    "        kernel = path_parts[2]\n",
    "        token = path_parts[3]\n",
    "    except IndexError:\n",
    "        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n",
    "\n",
    "    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n",
    "    url = f\"{PROXY_HOST}{url_prefix}\"\n",
    "\n",
    "    styled_html = f\"\"\"\n",
    "    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n",
    "            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n",
    "        </div>\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n",
    "            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n",
    "            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n",
    "                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n",
    "                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n",
    "                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n",
    "            </ol>\n",
    "            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n",
    "        </div>\n",
    "        <a href='{url}' target='_blank' style=\"\n",
    "            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n",
    "            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n",
    "            Open ADK Web UI (after running cell below) ‚Üó\n",
    "        </a>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    display(HTML(styled_html))\n",
    "\n",
    "    return url_prefix\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß© Purpose Summary\n",
    "\n",
    "This code defines a helper function get_adk_proxy_url() that helps connect to and open the Google ADK (Agent Development Kit) Web UI inside a Kaggle Notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Configure Retry Options\n",
    "\n",
    "Handle transient errors like rate limits with exponential backoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retry configuration set.\n"
     ]
    }
   ],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,  # Initial delay before first retry (seconds)\n",
    "    http_status_codes=[429, 500, 503, 504]  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Retry configuration set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Building Your First AI Agent\n",
    "\n",
    "### Objective\n",
    "Create a single agent that can search for current information and provide informed responses.\n",
    "\n",
    "### What You'll Learn\n",
    "- How to configure an agent with a model, instructions, and tools\n",
    "- How agents use tools to access real-time information\n",
    "- The difference between static LM responses and agent-powered responses\n",
    "\n",
    "### ü§î What is an AI Agent?\n",
    "\n",
    "You've probably used an LLM like Gemini before, where you give it a prompt and it gives you a text response.\n",
    "\n",
    "`Prompt -> LLM -> Text`\n",
    "\n",
    "An AI Agent takes this one step further. An agent can think, take actions, and observe the results of those actions to give you a better answer.\n",
    "\n",
    "`Prompt -> Agent -> Thought -> Action -> Observation -> Final Answer`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Your First Agent\n",
    "\n",
    "We'll create an agent with:\n",
    "- **Model**: Gemini 2.5 Flash Lite (fast, efficient)\n",
    "- **Instruction**: Clear guidance on when to use tools\n",
    "- **Tools**: Google Search for current information\n",
    "\n",
    "These are the main properties we'll set:\n",
    "\n",
    "- **name** and **description**: A simple name and description to identify our agent.\n",
    "- **model**: The specific LLM that will power the agent's reasoning. We'll use \"gemini-2.5-flash-lite\".\n",
    "- **instruction**: The agent's guiding prompt. This tells the agent what its goal is and how to behave.\n",
    "- **tools**: A list of [tools](https://google.github.io/adk-docs/tools/) that the agent can use. To start, we'll give it the `google_search` tool, which lets it find up-to-date information online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Root Agent defined.\n"
     ]
    }
   ],
   "source": [
    "# Create a helpful assistant agent with Google Search capability\n",
    "root_agent = Agent(\n",
    "    name=\"helpful_assistant\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    description=\"A simple agent that can answer general questions.\",\n",
    "    instruction=\"You are a helpful assistant. Use Google Search for current info or if unsure.\",\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Root Agent defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run Your Agent\n",
    "\n",
    "Create a runner and send a query that requires current information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runner created.\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > What is Agent Development Kit from Google? What languages is the SDK available in?\n",
      "helpful_assistant > The Agent Development Kit (ADK) from Google is a flexible and modular framework designed to simplify the development, deployment, and orchestration of AI agents and multi-agent systems. It applies software development principles to AI agent creation, aiming to make building complex agentic architectures feel more like traditional software development. While optimized for Google's Gemini models and ecosystem, ADK is model-agnostic and can be used with other frameworks.\n",
      "\n",
      "The ADK allows developers to define agent logic, tools, and orchestration directly in code, offering benefits such as robust debugging, reliable versioning, and deployment flexibility. It supports a rich tool ecosystem, including pre-built tools, custom functions, and third-party integrations. ADK also facilitates the creation of modular multi-agent systems where specialized agents can collaborate.\n",
      "\n",
      "The SDK is available in the following languages:\n",
      "*   **Python**\n",
      "*   **Java**\n",
      "*   **Go**\n"
     ]
    }
   ],
   "source": [
    "# Create a runner for the agent\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "print(\"‚úÖ Runner created.\")\n",
    "\n",
    "# Ask about ADK - requires current information\n",
    "response = await runner.run_debug(\n",
    "    \"What is Agent Development Kit from Google? What languages is the SDK available in?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Try Your Own Query\n",
    "\n",
    "Test the agent with a question requiring current information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > What's the weather in London?\n",
      "helpful_assistant > The weather in London is currently cloudy with a temperature of 58¬∞F (14¬∞C). There is a 0% chance of rain today. The humidity is around 79%.\n",
      "\n",
      "The forecast for the next few days includes a chance of light rain and clouds. Temperatures are expected to range from the low 50s¬∞F to the low 60s¬∞F (around 11¬∞C to 16¬∞C) over the next week.\n"
     ]
    }
   ],
   "source": [
    "# Try asking about current events or information\n",
    "response = await runner.run_debug(\"What's the weather in London?\")\n",
    "\n",
    "# Feel free to modify the query above and try:\n",
    "# - \"Who won the last soccer world cup?\"\n",
    "# - \"What new movies are showing in theaters now?\"\n",
    "# - Your own question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Task 1 Reflection\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. The agent didn't just respond - it **reasoned** that it needed more information\n",
    "2. It **acted** by using the Google Search tool\n",
    "3. It **observed** the results and formulated an answer\n",
    "4. This ability to take action is the foundation of agent-based AI\n",
    "\n",
    "**What's Next?**\n",
    "A single agent is powerful, but complex tasks require teams. Let's build multi-agent systems!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Section 3: Try the ADK Web Interface\n",
    "\n",
    "### Overview\n",
    "\n",
    "ADK includes a built-in web interface for interactively chatting with, testing, and debugging your agents.\n",
    "\n",
    "<img width=\"1200\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/adk-web-ui.gif\" alt=\"ADK Web UI\" />\n",
    "\n",
    "To use the ADK web UI, you'll need to create an agent with Python files using the `adk create` command.\n",
    "\n",
    "Run the command below to generate a `sample-agent` folder that contains all the necessary files, including `agent.py` for your code, an `.env` file with your API key pre-configured, and an `__init__.py` file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Multi-Agent Systems & Workflow Patterns\n",
    "\n",
    "### Objective\n",
    "Build specialized agent teams that collaborate using different workflow patterns.\n",
    "\n",
    "### The Problem with Monolithic Agents\n",
    "Single \"do-it-all\" agents become:\n",
    "- Hard to debug (which part failed?)\n",
    "- Difficult to maintain (long, complex instructions)\n",
    "- Unreliable (trying to do too much)\n",
    "\n",
    "### The Solution: Team of Specialists\n",
    "Multiple simple agents, each with one clear job, collaborating like a real team.\n",
    "\n",
    "\n",
    "**Architecture: Single Agent vs Multi-Agent Team**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 1: LLM-Based Orchestration\n",
    "\n",
    "Let an LLM coordinator decide which specialist agents to call and when.\n",
    "\n",
    "**Example: Research & Summarization System**\n",
    "\n",
    "\n",
    "1. **Research Agent** - Searches for information using Google Search\n",
    "2. **Summarizer Agent** - Creates concise summaries from research findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ research_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Research Agent: Searches for information\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n",
    "    google_search tool to find 2-3 pieces of relevant information on the given topic \n",
    "    and present the findings with citations.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ research_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ summarizer_agent created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summarizer Agent: Creates concise summaries\n",
    "summarizer_agent = Agent(\n",
    "    name=\"SummarizerAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Read the provided research findings: {research_findings}\n",
    "Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ summarizer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ root_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Root Coordinator: Orchestrates the workflow\n",
    "root_agent = Agent(\n",
    "    name=\"ResearchCoordinator\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
    "1. First, you MUST call the `ResearchAgent` tool to find relevant information.\n",
    "2. Next, after receiving findings, you MUST call the `SummarizerAgent` tool.\n",
    "3. Finally, present the final summary clearly to the user.\"\"\",\n",
    "    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ root_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM-orchestrated multi-agent system created.\n"
     ]
    }
   ],
   "source": [
    "# Research Agent: Searches for information\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n",
    "    google_search tool to find 2-3 pieces of relevant information on the given topic \n",
    "    and present the findings with citations.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\",\n",
    ")\n",
    "\n",
    "# Summarizer Agent: Creates concise summaries\n",
    "summarizer_agent = Agent(\n",
    "    name=\"SummarizerAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Read the provided research findings: {research_findings}\n",
    "Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "# Root Coordinator: Orchestrates the workflow\n",
    "root_agent = Agent(\n",
    "    name=\"ResearchCoordinator\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
    "1. First, you MUST call the `ResearchAgent` tool to find relevant information.\n",
    "2. Next, after receiving findings, you MUST call the `SummarizerAgent` tool.\n",
    "3. Finally, present the final summary clearly to the user.\"\"\",\n",
    "    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM-orchestrated multi-agent system created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > What are the latest advancements in quantum computing and what do they mean for AI?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResearchCoordinator > Quantum AI is poised to revolutionize artificial intelligence by leveraging the immense computational power of quantum computers. Key advancements include:\n",
      "\n",
      "*   **Enhanced Computational Power & Speed:** Quantum computers can process vast amounts of data and explore numerous solutions simultaneously, drastically accelerating AI tasks like model training and complex simulations. Some quantum algorithms have demonstrated performance thousands of times faster than classical supercomputers.\n",
      "*   **Improved AI Capabilities & Optimization:** Quantum machine learning algorithms promise more efficient data processing for better pattern recognition and natural language processing. Additionally, quantum algorithms are expected to significantly enhance AI's optimization capabilities, crucial for complex problems in fields like supply chain management and financial modeling.\n",
      "*   **Sustainability & Hybrid Approaches:** Quantum AI models may require fewer parameters, potentially leading to reduced computational costs and energy consumption. In the near future, hybrid systems combining quantum and classical computers are expected to be utilized to refine AI results.\n",
      "\n",
      "While widespread commercial adoption is still several years away due to ongoing challenges in hardware and algorithm development, the field is progressing rapidly. Significant investments are being made, and quantum computing is becoming more accessible. Experts predict substantial market growth by 2035, highlighting the transformative potential of this technology. However, ethical considerations regarding cybersecurity, privacy, bias, and equitable access must be carefully addressed.\n"
     ]
    }
   ],
   "source": [
    "# Run the multi-agent system\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Sequential Workflow - The Assembly Line\n",
    "\n",
    "**Use Case**: When tasks must happen in a specific, guaranteed order.\n",
    "\n",
    "**Example: Blog Post Creation Pipeline**\n",
    "\n",
    "<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Blog Post Creation with Sequential Agents\n",
    "\n",
    "Let's build a system with three specialized agents:\n",
    "\n",
    "1. **Outline Agent** - Creates a blog outline for a given topic\n",
    "2. **Writer Agent** - Writes a blog post\n",
    "3. **Editor Agent** - Edits a blog post draft for clarity and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sequential Agent created.\n"
     ]
    }
   ],
   "source": [
    "# Outline Agent: Creates blog structure\n",
    "outline_agent = Agent(\n",
    "    name=\"OutlineAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Create a blog outline for the given topic with:\n",
    "    1. A catchy headline\n",
    "    2. An introduction hook\n",
    "    3. 3-5 main sections with 2-3 bullet points for each\n",
    "    4. A concluding thought\"\"\",\n",
    "    output_key=\"blog_outline\",\n",
    ")\n",
    "\n",
    "# Writer Agent: Writes full blog post\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Following this outline strictly: {blog_outline}\n",
    "    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n",
    "    output_key=\"blog_draft\",\n",
    ")\n",
    "\n",
    "# Editor Agent: Polishes the draft\n",
    "editor_agent = Agent(\n",
    "    name=\"EditorAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Edit this draft: {blog_draft}\n",
    "    Polish by fixing grammatical errors, improving flow and sentence structure, \n",
    "    and enhancing overall clarity.\"\"\",\n",
    "    output_key=\"final_blog\",\n",
    ")\n",
    "\n",
    "# Sequential Agent: Runs agents in fixed order\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"BlogPipeline\",\n",
    "    sub_agents=[outline_agent, writer_agent, editor_agent],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Sequential Agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Write a blog post about the benefits of multi-agent systems for software developers\n",
      "OutlineAgent > ## Blog Outline:\n",
      "\n",
      "**Headline:** Unleash the Power of Collaboration: How Multi-Agent Systems Will Revolutionize Your Development Workflow\n",
      "\n",
      "**Introduction Hook:** Imagine a world where your code writes itself, complex bugs are automatically squashed, and your development team operates with unprecedented efficiency. This isn't science fiction; it's the promise of Multi-Agent Systems (MAS). For software developers, understanding and leveraging MAS is no longer a niche interest but a pathway to a more powerful, agile, and innovative future.\n",
      "\n",
      "**Main Sections:**\n",
      "\n",
      "**1. What Exactly is a Multi-Agent System? (And Why Should You Care?)**\n",
      "    *   **Definition:** Briefly explain MAS as a system composed of multiple autonomous agents that interact with each other and their environment to achieve individual and collective goals.\n",
      "    *   **The \"Developer's Lens\":** Frame MAS not just as AI, but as intelligent, cooperative \"co-developers\" or \"assistants\" that can tackle discrete tasks within the software development lifecycle.\n",
      "    *   **Beyond Monolithic Code:** Highlight how MAS breaks down complex development into manageable, interconnected components, fostering modularity and scalability.\n",
      "\n",
      "**2. Supercharging Your Development Pipeline with MAS**\n",
      "    *   **Automated Task Execution:** Discuss how agents can be assigned repetitive or complex tasks like code generation, testing, debugging, and even deployment, freeing up human developers for higher-level problem-solving.\n",
      "    *   **Enhanced Collaboration & Communication:** Explain how MAS can facilitate smoother team interaction, provide real-time insights, and even mediate conflicts by offering objective data and solutions.\n",
      "    *   **Proactive Problem Detection & Resolution:** Detail how agents can continuously monitor code, identify potential issues *before* they become major bugs, and even propose or implement fixes autonomously.\n",
      "\n",
      "**3. Real-World Applications and Future Potential**\n",
      "    *   **Intelligent Code Completion & Generation:** Explore how MAS can go beyond basic auto-complete to generate entire code snippets, functions, or even boilerplate for complex architectures.\n",
      "    *   **Advanced Testing & Validation:** Discuss MAS agents performing sophisticated unit, integration, and performance testing, identifying edge cases and vulnerabilities humans might miss.\n",
      "    *   **Self-Healing & Adaptive Systems:** Touch upon the futuristic concept of MAS enabling software that can detect and repair errors, adapt to changing environments, and optimize performance autonomously.\n",
      "\n",
      "**4. Getting Started: Embracing the MAS Revolution**\n",
      "    *   **Learning the Fundamentals:** Suggest resources for understanding MAS concepts, architectures, and popular frameworks.\n",
      "    *   **Pilot Projects & Experimentation:** Encourage developers to start with small, well-defined MAS projects to gain practical experience and identify areas of immediate benefit.\n",
      "    *   **The Shift in Developer Mindset:** Emphasize the need to think about development as orchestrating intelligent agents rather than just writing lines of code.\n",
      "\n",
      "**Concluding Thought:** The era of the lone coder is evolving. By embracing Multi-Agent Systems, software developers can unlock a new level of productivity, innovation, and problem-solving power, paving the way for more robust, intelligent, and resilient software than ever before. The future of development is collaborative, and MAS is leading the charge.\n",
      "WriterAgent > ## Unleash the Power of Collaboration: How Multi-Agent Systems Will Revolutionize Your Development Workflow\n",
      "\n",
      "Imagine a world where your code writes itself, complex bugs are automatically squashed, and your development team operates with unprecedented efficiency. This isn't science fiction; it's the promise of Multi-Agent Systems (MAS). For software developers, understanding and leveraging MAS is no longer a niche interest but a pathway to a more powerful, agile, and innovative future.\n",
      "\n",
      "At its core, a Multi-Agent System is a network of autonomous agents interacting to achieve individual and collective goals. Think of them not just as AI, but as intelligent, cooperative \"co-developers\" or \"assistants\" tackling discrete tasks within your software development lifecycle. This breaks down complex development into manageable, interconnected components, fostering modularity and scalability.\n",
      "\n",
      "How can MAS supercharge your pipeline? Agents can automate repetitive tasks like code generation, testing, and debugging, freeing you for higher-level problem-solving. They can enhance team collaboration by providing real-time insights and even mediating conflicts. Crucially, MAS agents can proactively monitor your code, identifying potential issues *before* they become major bugs and even proposing or implementing fixes autonomously.\n",
      "\n",
      "The potential applications are vast: intelligent code completion that generates entire functions, advanced testing that uncovers obscure edge cases, and even self-healing systems that adapt and repair themselves. Embracing this revolution means learning the fundamentals, experimenting with pilot projects, and shifting your mindset to orchestrating intelligent agents. The future of development is collaborative, and MAS is leading the charge to more robust, intelligent, and resilient software.\n",
      "EditorAgent > ## Unleash the Power of Collaboration: How Multi-Agent Systems Will Revolutionize Your Development Workflow\n",
      "\n",
      "Imagine a world where your code writes itself, complex bugs are automatically squashed, and your development team operates with unprecedented efficiency. This isn't science fiction; it's the promise of Multi-Agent Systems (MAS). For software developers, understanding and leveraging MAS is no longer a niche interest but a pathway to a more powerful, agile, and innovative future.\n",
      "\n",
      "### What Exactly is a Multi-Agent System? (And Why Should You Care?)\n",
      "\n",
      "At its core, a Multi-Agent System is a network of autonomous agents that interact with each other and their environment to achieve individual and collective goals. But for developers, think of them not just as abstract AI, but as intelligent, cooperative \"co-developers\" or \"assistants.\" These agents can be assigned discrete tasks within your software development lifecycle. This approach breaks down complex development into manageable, interconnected components, fostering modularity and scalability far beyond traditional methods.\n",
      "\n",
      "### Supercharging Your Development Pipeline with MAS\n",
      "\n",
      "How can MAS truly supercharge your workflow? The potential is immense:\n",
      "\n",
      "*   **Automated Task Execution:** Agents can shoulder the burden of repetitive or time-consuming tasks like code generation, comprehensive testing, and intricate debugging. This frees human developers to focus on higher-level problem-solving, architectural design, and innovation.\n",
      "*   **Enhanced Collaboration & Communication:** MAS can facilitate smoother team interaction. Agents can provide real-time insights into project status, flag potential bottlenecks, and even act as impartial mediators by offering objective data and potential solutions to team conflicts.\n",
      "*   **Proactive Problem Detection & Resolution:** Imagine agents continuously monitoring your codebase, identifying potential issues *before* they escalate into major bugs. Even more powerfully, they can proactively propose or autonomously implement fixes, drastically reducing downtime and costly rework.\n",
      "\n",
      "### Real-World Applications and Future Potential\n",
      "\n",
      "The applications for MAS in software development are vast and continually expanding:\n",
      "\n",
      "*   **Intelligent Code Completion & Generation:** Beyond basic auto-complete, MAS agents can generate entire code snippets, complex functions, or even boilerplate code for intricate architectures based on context and project requirements.\n",
      "*   **Advanced Testing & Validation:** MAS agents can perform sophisticated unit, integration, and performance testing, uncovering obscure edge cases and vulnerabilities that human testers might overlook.\n",
      "*   **Self-Healing & Adaptive Systems:** In the future, MAS could enable software that can detect and repair errors in real-time, adapt to changing operational environments, and optimize its own performance autonomously.\n",
      "\n",
      "### Getting Started: Embracing the MAS Revolution\n",
      "\n",
      "To harness the power of MAS, developers should consider:\n",
      "\n",
      "*   **Learning the Fundamentals:** Explore resources to understand MAS concepts, common architectures, and popular frameworks.\n",
      "*   **Pilot Projects & Experimentation:** Begin with small, well-defined MAS projects. This practical experience will help identify areas where MAS can deliver immediate benefits to your team.\n",
      "*   **The Shift in Developer Mindset:** Embrace a new way of thinking. Development will increasingly involve orchestrating and collaborating with intelligent agents, rather than solely writing individual lines of code.\n",
      "\n",
      "The era of the lone coder is evolving. By embracing Multi-Agent Systems, software developers can unlock a new level of productivity, innovation, and problem-solving power. This collaborative approach paves the way for more robust, intelligent, and resilient software than ever before. The future of development is here, and MAS is leading the charge.\n"
     ]
    }
   ],
   "source": [
    "# Run the sequential pipeline\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: Parallel Workflow - Independent Researchers\n",
    "\n",
    "**Use Case**: When tasks are independent and can run simultaneously for speed.\n",
    "\n",
    "**The Solution: Concurrent Execution**\n",
    "\n",
    "When you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n",
    "\n",
    "**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n",
    "\n",
    "**Example: Multi-Topic Research**\n",
    "\n",
    "<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Parallel Multi-Topic Research\n",
    "\n",
    "Let's build a system with four agents:\n",
    "\n",
    "1. **Tech Researcher** - Researches AI/ML news and trends\n",
    "2. **Health Researcher** - Researches recent medical news and trends\n",
    "3. **Finance Researcher** - Researches finance and fintech news and trends\n",
    "4. **Aggregator Agent** - Combines all research findings into a single summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parallel and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# Create three specialized researchers\n",
    "tech_researcher = Agent(\n",
    "    name=\"TechResearcher\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\n",
    "the main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"tech_research\",\n",
    ")\n",
    "\n",
    "health_researcher = Agent(\n",
    "    name=\"HealthResearcher\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\n",
    "their practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"health_research\",\n",
    ")\n",
    "\n",
    "finance_researcher = Agent(\n",
    "    name=\"FinanceResearcher\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\n",
    "their market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"finance_research\",\n",
    ")\n",
    "\n",
    "# Aggregator combines all research\n",
    "aggregator_agent = Agent(\n",
    "    name=\"AggregatorAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Combine these three research findings into a single executive summary:\n",
    "\n",
    " **Technology Trends:** {tech_research}\n",
    " **Health Breakthroughs:** {health_research}\n",
    " **Finance Innovations:** {finance_research}\n",
    " \n",
    " Highlight common themes, surprising connections, and key takeaways. \n",
    " Final summary should be around 200 words.\"\"\",\n",
    "    output_key=\"executive_summary\",\n",
    ")\n",
    "\n",
    "# Parallel execution then sequential aggregation\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"ParallelResearchTeam\",\n",
    "    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n",
    ")\n",
    "\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"ResearchSystem\",\n",
    "    sub_agents=[parallel_research_team, aggregator_agent],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Parallel and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Run the daily executive briefing on Tech, Health, and Finance\n",
      "HealthResearcher > Here are three recent medical breakthroughs:\n",
      "\n",
      "1.  **AI-driven Sepsis Detection:** Artificial intelligence algorithms can now detect sepsis nearly six hours earlier than traditional methods.\n",
      "    *   **Application:** This allows for faster treatment, significantly reducing sepsis-related deaths and hospitalizations. It's also being adapted to predict kidney and heart failure.\n",
      "    *   **Timeline:** Already being implemented in hospitals, with widespread adoption expected within the next 1-2 years.\n",
      "\n",
      "2.  **Gene Sequencing for Rare Diseases:** Rapid gene sequencing is identifying dangerous mutations, aiding in the diagnosis of rare genetic disorders.\n",
      "    *   **Application:** Enables earlier and more accurate diagnoses, leading to targeted therapies and improved patient outcomes.\n",
      "    *   **Timeline:** Advanced gene sequencing is increasingly accessible, with significant impact on diagnosis timelines within the next 2-3 years.\n",
      "\n",
      "3.  **Vaccines for RSV:** The first-ever vaccines to protect against Respiratory Syncytial Virus (RSV) have been approved.\n",
      "    *   **Application:** Prevents severe illness and hospitalization from RSV, particularly in older adults and young children.\n",
      "    *   **Timeline:** Vaccines are already approved and rolling out, with widespread availability and impact expected within the next year.\n",
      "TechResearcher > Here's a concise report on the latest AI/ML trends:\n",
      "\n",
      "**Key AI/ML Developments in 2025:**\n",
      "\n",
      "1.  **Generative AI Unleashed:** Beyond content creation, Generative AI is now creating new proteins, materials, and solving complex scientific problems. Companies like **Google** (with Muse and Imagen) and **OpenAI** are at the forefront, impacting drug discovery and materials science.\n",
      "2.  **Agentic AI and Autonomous Systems:** AI systems capable of autonomous action are rising. These \"agents\" can perceive, reason, and act independently, transforming fields like finance and logistics. **Microsoft** (with Copilot) and **AVIA** (with Nexus Agentic AI) are key players.\n",
      "3.  **Edge AI Expansion:** AI processing is increasingly moving to devices, enabling real-time, low-latency decision-making with improved data privacy. This is crucial for industries like autonomous vehicles and smart cities.\n",
      "\n",
      "**Main Companies Involved:** Major tech giants such as **Google**, **Microsoft**, **Nvidia**, **OpenAI**, **Amazon**, and **Meta** are heavily investing and innovating across these trends.\n",
      "\n",
      "**Potential Impact:** These advancements promise unprecedented efficiencies, accelerate scientific discovery, enable new forms of automation, and personalize user experiences across industries like healthcare, finance, and manufacturing.\n",
      "FinanceResearcher > ## Daily Executive Briefing - November 12, 2025\n",
      "\n",
      "**Technology:**\n",
      "\n",
      "The AI market continues its rapid expansion, with AMD highlighting a potential $1 trillion opportunity in the sector. This growth is fueled by increased demand for AI computing capacity, as evidenced by Meta's $3 billion agreement with Nebius. Google is also investing heavily, committing $6.4 billion to German data centers by 2029. The integration of AI into government services is a key focus, with discussions on improving public services and cybersecurity through AI.\n",
      "\n",
      "**Health:**\n",
      "\n",
      "The 2025 Executive Health Care Conference will convene leaders to address healthcare transformation through collaboration and innovation. Key themes include managing risk with value-based care, navigating federal and state legislation, and the role of AI in healthcare delivery. A particular focus is on leadership in cultivating wellness and mitigating burnout, with strategies for harnessing technology and addressing secondary trauma.\n",
      "\n",
      "**Finance:**\n",
      "\n",
      "Financial executives are preparing for year-end priorities, with a focus on audit quality and accounting standards, as regulators prepare to speak at the CFRI 2025 conference. Economic updates will address navigating uncertain times, with experts predicting recessions and offering insights on managing trade risk. The impact of AI on risk management, particularly in credit risk, is also a growing concern.\n",
      "\n",
      "---\n",
      "\n",
      "### Fintech Trends:\n",
      "\n",
      "1.  **Embedded Finance:** Financial services are increasingly integrated into non-financial platforms (e.g., e-commerce checkout, ride-sharing apps).\n",
      "    *   **Market Implications:** Increased customer convenience, new revenue streams for tech companies, and greater financial inclusion.\n",
      "    *   **Future Outlook:** Continued expansion, blurring lines between traditional banking and other industries, with a focus on seamless user experiences.\n",
      "\n",
      "2.  **AI and Machine Learning in Financial Services:** AI is revolutionizing areas like fraud detection, credit scoring, personalized financial advice, and algorithmic trading.\n",
      "    *   **Market Implications:** Improved efficiency, reduced operational costs, enhanced risk management, and hyper-personalized customer offerings.\n",
      "    *   **Future Outlook:** Deeper integration across all financial operations, sophisticated predictive analytics, and more advanced AI-driven financial advisors.\n",
      "\n",
      "3.  **Decentralized Finance (DeFi):** While still emerging, DeFi aims to create open, permissionless, and transparent financial systems using blockchain technology, bypassing traditional intermediaries.\n",
      "    *   **Market Implications:** Potential for lower transaction costs, increased accessibility to financial products, and greater user control over assets.\n",
      "    *   **Future Outlook:** Maturation of the technology, increased regulatory clarity, and potential for mainstream adoption as security and scalability challenges are addressed.\n",
      "AggregatorAgent > ## Executive Summary: Cross-Sector Innovations Driven by AI\n",
      "\n",
      "Artificial Intelligence (AI) is the unifying force behind significant advancements across technology, health, and finance. In **technology**, generative AI is moving beyond content creation to solve complex scientific problems, while agentic AI and edge AI are enabling autonomous systems and real-time, privacy-preserving decision-making. Major tech players like Google, Microsoft, and OpenAI are leading this rapid expansion, which is creating a trillion-dollar market opportunity.\n",
      "\n",
      "This AI revolution is profoundly impacting **healthcare**. AI-driven algorithms are now detecting sepsis hours earlier, significantly reducing mortality, and gene sequencing is accelerating rare disease diagnoses. The approval of the first RSV vaccines further highlights a proactive approach to public health. These breakthroughs, coupled with a focus on AI in healthcare delivery at the 2025 Executive Health Care Conference, point towards a future of more personalized and effective patient care.\n",
      "\n",
      "In **finance**, AI is transforming risk management, fraud detection, and personalized financial advice, leading to increased efficiency and reduced operational costs. The growth of embedded finance further integrates financial services into everyday platforms, while Decentralized Finance (DeFi) explores new, transparent financial systems. Despite economic uncertainties and a focus on audit quality, AI's pervasive influence promises to reshape financial operations and customer experiences.\n",
      "\n",
      "**Key Takeaway:** The convergence of advanced AI capabilities with specific sector needs is driving unprecedented innovation, promising enhanced efficiencies, accelerated discovery, and more personalized services across the board.\n"
     ]
    }
   ],
   "source": [
    "# Run parallel research with aggregation\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Run the daily executive briefing on Tech, Health, and Finance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 4: Loop Workflow - The Refinement Cycle\n",
    "\n",
    "**Use Case**: When output needs iterative improvement through feedback cycles.\n",
    "\n",
    "**Example: Story Writing & Critique Loop**\n",
    "\n",
    "<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loop and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# Initial Writer: Creates first draft\n",
    "initial_writer_agent = Agent(\n",
    "    name=\"InitialWriterAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story \n",
    "    (around 100-150 words). Output only the story text, with no introduction or explanation.\"\"\",\n",
    "    output_key=\"current_story\",\n",
    ")\n",
    "\n",
    "# Critic: Provides feedback or approval\n",
    "critic_agent = Agent(\n",
    "    name=\"CriticAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a constructive story critic. Review the story: {current_story}\n",
    "    \n",
    "    Evaluate plot, characters, and pacing.\n",
    "    - If the story is well-written and complete, respond EXACTLY: \"APPROVED\"\n",
    "    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n",
    "    output_key=\"critique\",\n",
    ")\n",
    "\n",
    "# Exit function for loop termination\n",
    "def exit_loop():\n",
    "    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating \n",
    "    the story is finished and no more changes are needed.\"\"\"\n",
    "    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n",
    "\n",
    "# Refiner: Improves story or exits loop\n",
    "refiner_agent = Agent(\n",
    "    name=\"RefinerAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a story refiner. You have:\n",
    "    Story Draft: {current_story}\n",
    "    Critique: {critique}\n",
    "    \n",
    "    Analyze the critique:\n",
    "    - IF critique is EXACTLY \"APPROVED\", call the `exit_loop` function and nothing else.\n",
    "    - OTHERWISE, rewrite the story to fully incorporate the feedback.\"\"\",\n",
    "    output_key=\"current_story\",\n",
    "    tools=[FunctionTool(exit_loop)],\n",
    ")\n",
    "\n",
    "# Loop for refinement cycles\n",
    "story_refinement_loop = LoopAgent(\n",
    "    name=\"StoryRefinementLoop\",\n",
    "    sub_agents=[critic_agent, refiner_agent],\n",
    "    max_iterations=2,  # Prevents infinite loops\n",
    ")\n",
    "\n",
    "# Root Sequential Agent: Initial Write ‚Üí Refinement Loop\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"StoryPipeline\",\n",
    "    sub_agents=[initial_writer_agent, story_refinement_loop],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Loop and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\n",
      "InitialWriterAgent > Elias traced the salt-laced lines on the storm-battered parchment. It wasn't paper, not quite. It felt more like woven moonlight, cool and impossibly smooth beneath his calloused fingertips. He‚Äôd found it tucked inside a barnacle-encrusted sea chest that had washed ashore after the last tempest. The map depicted no known coastline, but strange, swirling constellations and a single, pulsating emerald dot at its center. As he held it, the dot flared, projecting a faint, spectral beam onto the lighthouse wall. Elias shivered, a prickle of both fear and exhilaration racing down his spine. The sea, it seemed, still held secrets he'd never dreamed of.\n",
      "CriticAgent > The story is a compelling start, hinting at a grand adventure. Here are a few suggestions to enhance it:\n",
      "\n",
      "*   **Character Depth:** While Elias's initial reaction is well-described, consider adding a brief detail about his life or personality before this discovery. Is he a solitary man, yearning for something more, or content with his routine? A touch of this could make his fear and exhilaration more impactful.\n",
      "*   **World-Building Nuance:** The \"woven moonlight\" parchment is a fantastic, evocative detail. To further immerse the reader, you could briefly hint at the *origin* of such material, even if it's just a whispered legend or a thought Elias has. Is it from a mythical place, or is it simply unlike anything he's ever encountered in his earthly experience?\n",
      "*   **Pacing and Foreshadowing:** The current pacing is good for a short snippet. However, for a longer story, you might consider what the *next* immediate step is. Does Elias try to decipher the map further? Does the spectral beam lead him to another object, or does it fade? A small hint of the immediate future could increase anticipation.\n",
      "RefinerAgent > Elias traced the salt-laced lines on the storm-battered parchment, a familiar ache in his solitary existence momentarily forgotten. For twenty years, the rhythm of his life had been the crashing waves and the steady sweep of the lighthouse beam. He was a man content, or so he'd told himself, with the predictable isolation. But this parchment, found tucked inside a barnacle-encrusted sea chest that had washed ashore after the last tempest, pulsed with an unknown energy. It wasn't paper, not quite. It felt more like woven moonlight, a material whispered about in sailors' myths, impossibly smooth beneath his calloused fingertips. Legends spoke of such fabric originating from the star-dusted shores of a realm beyond the veil of the ordinary world.\n",
      "\n",
      "The map depicted no known coastline, only strange, swirling constellations and a single, pulsating emerald dot at its center. As Elias held it, the dot flared, projecting a faint, spectral beam onto the lighthouse wall. It illuminated a section of stone that had always seemed unremarkable, now shimmering with an otherworldly light. Elias shivered, a prickle of both fear and exhilaration racing down his spine. The sea, it seemed, still held secrets he'd never dreamed of, and this map was an invitation. He took a step closer to the glowing wall, wondering if the beam would fade or if it was merely the first step in a journey that would pull him from his quiet, predictable life.\n",
      "CriticAgent > APPROVED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    }
   ],
   "source": [
    "# Run the story refinement system\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Task 2 Reflection: Choosing the Right Pattern\n",
    "\n",
    "**Decision Tree: Which Workflow Pattern?**\n",
    "\n",
    "| Pattern | When to Use | Example | Key Feature |\n",
    "|---------|-------------|---------|-------------|\n",
    "| **LLM-based Orchestration** | Dynamic decisions needed | Research + Summarize | LLM decides what to call |\n",
    "| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n",
    "| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n",
    "| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |\n",
    "\n",
    "<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Multi-agent systems scale better than monolithic agents\n",
    "- Choose patterns based on task requirements (order, independence, iteration)\n",
    "- Use `output_key` for state passing between agents\n",
    "- Always include safeguards like `max_iterations` in loops\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:meta]",
   "language": "python",
   "name": "conda-env-meta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
