{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Engineering: Sessions & Memory\n",
    "\n",
    "**Course Day:** Day 2\n",
    "\n",
    "**Description:** Learn how to build stateful, intelligent LLM agents through Context Engineering - the dynamic assembly and management of information within an LLM's context window. Master Sessions for short-term conversation management and Memory for long-term persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Understand Context Engineering and its role in building stateful AI agents\n",
    "- Implement Sessions to manage conversation history and working memory\n",
    "- Build Memory systems for long-term persistence across multiple sessions\n",
    "- Apply memory generation techniques (extraction and consolidation)\n",
    "- Implement memory retrieval strategies for relevant context\n",
    "- Handle multi-agent systems with shared and separate session histories\n",
    "- Optimize long-context conversations through compaction strategies\n",
    "- Deploy production-ready session and memory management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Engineering\n",
    "\n",
    "**Definition:** The process of dynamically assembling and managing information within an LLM's context window to enable stateful, intelligent agents\n",
    "\n",
    "**Evolution:** Evolved from Prompt Engineering (static system instructions) to dynamic, state-aware prompt construction\n",
    "\n",
    "**Analogy:** Like mise en place for a chef - gathering and preparing all ingredients before cooking to ensure excellent results\n",
    "\n",
    "#### Components\n",
    "\n",
    "**Context to Guide Reasoning:**\n",
    "- System Instructions: High-level directives defining agent's persona and capabilities\n",
    "- Tool Definitions: Schemas for APIs or functions the agent can use\n",
    "- Few-Shot Examples: Curated examples for in-context learning\n",
    "\n",
    "**Evidential & Factual Data:**\n",
    "- Long-Term Memory: Persisted knowledge across multiple sessions\n",
    "- External Knowledge: Information from RAG databases or documents\n",
    "- Tool Outputs: Data returned by tool calls\n",
    "- Sub-Agent Outputs: Results from specialized agents\n",
    "- Artifacts: Non-textual data (files, images)\n",
    "\n",
    "**Immediate Conversational Information:**\n",
    "- Conversation History: Turn-by-turn record of current interaction\n",
    "- State/Scratchpad: Temporary in-progress information\n",
    "- User's Prompt: The immediate query to address\n",
    "\n",
    "#### Lifecycle\n",
    "1. Fetch Context: Retrieve user memories, RAG documents, recent events\n",
    "2. Prepare Context: Dynamically construct the full prompt (blocking process)\n",
    "3. Invoke LLM and Tools: Iteratively call LLM and tools until response generated\n",
    "4. Upload Context: Persist new information to storage (background process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions\n",
    "\n",
    "**Definition:** A container for an entire conversation with an agent, holding chronological history and working memory\n",
    "\n",
    "**Characteristics:**\n",
    "- Self-contained record tied to a specific user\n",
    "- Functions as temporary 'workbench' for single conversation\n",
    "- Contains Events (building blocks) and State (working memory)\n",
    "- Requires persistent storage for production (e.g., Agent Engine Sessions)\n",
    "\n",
    "**Event Types:**\n",
    "- User Input: Messages from user (text, audio, image, etc.)\n",
    "- Agent Response: Agent's reply to user\n",
    "- Tool Call: Agent's decision to use external tool/API\n",
    "- Tool Output: Data returned from tool call\n",
    "\n",
    "**State Definition:** Structured 'working memory' or scratchpad holding temporary data like shopping cart items\n",
    "\n",
    "**Storage Requirements:**\n",
    "- **Development:** In-memory storage acceptable\n",
    "- **Production:** Robust databases (Agent Engine Sessions, Spanner, Redis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "**Definition:** The mechanism for long-term persistence, capturing and consolidating key information across multiple sessions\n",
    "\n",
    "**Analogy:** Like an organized filing cabinet - reviewing desk materials, discarding drafts, filing critical documents\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Personalization: Remember user preferences and past interactions\n",
    "- Context Window Management: Compact history via summaries and facts\n",
    "- Data Mining: Extract insights from conversations\n",
    "- Agent Self-Improvement: Learn from previous runs via procedural memories\n",
    "\n",
    "#### Memory vs RAG\n",
    "\n",
    "| Aspect              | Memory                                                                 | RAG                                                                 |\n",
    "|---------------------|------------------------------------------------------------------------|---------------------------------------------------------------------|\n",
    "| **Goal**            | Create personalized, stateful experience                               | Inject external, factual knowledge                                  |\n",
    "| **Data Source**     | Dialogue between user and agent                                        | Static, pre-indexed knowledge base                                  |\n",
    "| **Isolation**       | Highly isolated per-user                                               | Generally shared across users                                       |\n",
    "| **Information Type**| Dynamic, user-specific, uncertain                                      | Static, factual, authoritative                                      |\n",
    "| **Write Pattern**   | Event-based processing (every turn or session end)                     | Batch processing (offline)                                          |\n",
    "| **Read Pattern**    | Memory-as-a-tool or static retrieval                                   | Retrieved as-a-tool when needed                                     |\n",
    "| **Data Format**     | Natural language snippet or structured profile                         | Natural-language chunk                                              |\n",
    "| **Preparation**     | Extraction and consolidation                                           | Chunking and indexing                                               |\n",
    "\n",
    "**Analogy:** RAG is research librarian (expert on facts), Memory is personal assistant (expert on user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Types\n",
    "\n",
    "#### By Information Type\n",
    "\n",
    "**Declarative:**\n",
    "- Definition: Knowledge of facts, figures, and events (knowing what)\n",
    "- Examples: User preferences, Past interactions, Entity facts\n",
    "\n",
    "**Procedural:**\n",
    "- Definition: Knowledge of skills and workflows (knowing how)\n",
    "- Examples: Tool call sequences, Successful strategies, Best practices playbooks\n",
    "\n",
    "#### By Organization\n",
    "- **Collections:** Multiple self-contained natural language memories per user\n",
    "- **Structured Profile:** Set of core facts like contact card (quick lookups)\n",
    "- **Rolling Summary:** Single evolving summary of entire user-agent relationship\n",
    "\n",
    "#### By Storage\n",
    "- **Vector Databases:** Semantic similarity search for conceptually similar memories\n",
    "- **Knowledge Graphs:** Network of entities and relationships for complex connections\n",
    "- **Hybrid:** Combines both for structured reasoning and semantic search\n",
    "\n",
    "#### By Creation\n",
    "- **Explicit:** User directly commands agent to remember (e.g., 'Remember my anniversary')\n",
    "- **Implicit:** Agent infers and extracts from conversation without direct command\n",
    "\n",
    "#### By Scope\n",
    "- **User Level:** Tied to specific user ID, persists across all sessions\n",
    "- **Session Level:** Compaction of single conversation, isolated to that session\n",
    "- **Application Level:** Accessible by all users (e.g., procedural memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Generation\n",
    "\n",
    "**Definition:** LLM-driven ETL pipeline that transforms raw conversational data into structured insights\n",
    "\n",
    "#### Stages\n",
    "1. Ingestion: Client provides raw data (conversation history)\n",
    "2. Extraction & Filtering: LLM extracts meaningful content matching topic definitions\n",
    "3. Consolidation: Self-editing process comparing new info with existing memories\n",
    "4. Storage: Persist to durable storage (vector database or knowledge graph)\n",
    "\n",
    "#### Extraction Methods\n",
    "- **Schema Based:** LLM follows predefined JSON schema using structured output\n",
    "- **Natural Language:** LLM guided by natural language topic descriptions\n",
    "- **Few-Shot:** LLM learns from examples showing ideal memory extraction\n",
    "\n",
    "#### Consolidation Operations\n",
    "- UPDATE: Modify existing memory with new/corrected information\n",
    "- CREATE: Add entirely novel memory unrelated to existing ones\n",
    "- DELETE/INVALIDATE: Remove incorrect or irrelevant old memories\n",
    "\n",
    "#### Consolidation Challenges\n",
    "- Information Duplication: Same fact mentioned multiple ways\n",
    "- Conflicting Information: User's state changes over time\n",
    "- Information Evolution: Simple facts become more nuanced\n",
    "- Memory Relevance Decay: Proactive pruning of stale memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Provenance\n",
    "\n",
    "**Definition:** Detailed record of memory's origin and history to assess trustworthiness\n",
    "\n",
    "**Importance:** Critical for evaluating memory quality during consolidation and inference\n",
    "\n",
    "**Source Types:**\n",
    "- Bootstrapped Data: Pre-loaded from internal systems (high trust)\n",
    "- User Input: Explicit (high trust) or implicit from conversation (lower trust)\n",
    "- Tool Output: From external tools (discouraged - brittle and stale)\n",
    "\n",
    "**Conflict Resolution Strategies:**\n",
    "- Prioritize most trusted source\n",
    "- Favor most recent information\n",
    "- Look for corroboration across multiple data points\n",
    "\n",
    "**Confidence Factors:**\n",
    "- **Increases:** Multiple trusted sources provide consistent information\n",
    "- **Decreases:** Time-based decay, contradictory information introduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Retrieval\n",
    "\n",
    "**Scoring Dimensions:**\n",
    "- Relevance (Semantic Similarity): Conceptual relation to current conversation\n",
    "- Recency (Time-based): How recently was memory created\n",
    "- Importance (Significance): Overall criticality of memory\n",
    "\n",
    "#### Advanced Techniques\n",
    "- **Query Rewriting:** LLM rewrites ambiguous input or expands to multiple queries\n",
    "- **Reranking:** Initial broad search, then LLM re-evaluates top results\n",
    "- **Specialized Retriever:** Train custom retriever via fine-tuning\n",
    "\n",
    "#### Timing Strategies\n",
    "- **Proactive Retrieval:** Auto-load at start of every turn (may add unnecessary latency)\n",
    "- **Reactive Retrieval:** Memory-as-a-tool where agent decides when to retrieve (more efficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with Memories\n",
    "\n",
    "#### Placement Options\n",
    "\n",
    "**System Instructions:**\n",
    "- Method: Append memories to system prompt with preamble\n",
    "- Advantages: High authority, Clean separation, Ideal for stable global info\n",
    "- Disadvantages: Risk of over-influence, Requires dynamic prompt construction, Incompatible with memory-as-a-tool\n",
    "\n",
    "**Conversation History:**\n",
    "- Method: Inject directly into turn-by-turn dialogue\n",
    "- Advantages: Works with memory-as-a-tool, Supports multimodal content\n",
    "- Disadvantages: Noisy/increases tokens, Risk of dialogue injection, Needs careful perspective management\n",
    "\n",
    "**Best Practice:** Hybrid strategy - system prompt for stable user profile, dialogue injection for transient episodic memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent Sessions\n",
    "\n",
    "### Shared Unified History\n",
    "- **Description:** All agents read/write to same single conversation history\n",
    "- **Use Case:** Tightly coupled collaborative tasks requiring single source of truth\n",
    "- **Example:** Multi-step problem-solving where one agent's output is direct input for next\n",
    "- **ADK Implementation:** LLM-driven delegation writes sub-agent events to same session\n",
    "\n",
    "### Separate Individual Histories\n",
    "- **Description:** Each agent maintains private conversation history\n",
    "- **Use Case:** Loosely coupled systems where agents function as black boxes\n",
    "- **Communication:** Via Agent-as-a-tool or Agent-to-Agent (A2A) Protocol\n",
    "- **Challenge:** Framework-specific schemas create isolation between different frameworks\n",
    "\n",
    "### Interoperability Solution\n",
    "- **Problem:** Session stores couple database schema to framework's internal objects\n",
    "- **Solution:** Abstract shared knowledge into framework-agnostic Memory layer\n",
    "- **Benefit:** Memory stores processed, canonical information as strings/dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Compaction\n",
    "\n",
    "### Motivation\n",
    "- Context Window Limits: LLMs have maximum text they can process\n",
    "- API Costs: Charges based on token count sent/received\n",
    "- Latency: More text takes longer to process\n",
    "- Quality: Performance degrades with increased noise and autoregressive errors\n",
    "\n",
    "### Strategies\n",
    "\n",
    "| Name                  | Description                                      | Pros                  | Cons                              |\n",
    "|-----------------------|--------------------------------------------------|-----------------------|-----------------------------------|\n",
    "| **Keep Last N Turns** | Sliding window - keep most recent N turns, discard older | Simple implementation | Loses potentially important context |\n",
    "| **Token-Based Truncation** | Count tokens backward from latest, include up to limit | Precise token management | Arbitrary cutoff may lose context |\n",
    "| **Recursive Summarization** | Replace older messages with AI-generated summary | Preserves key information while reducing tokens | Expensive (additional LLM calls) |\n",
    "\n",
    "### Trigger Mechanisms\n",
    "- Count-Based: Token size or turn count threshold\n",
    "- Time-Based: Lack of activity for set period\n",
    "- Event-Based: Semantic/task completion detected\n",
    "\n",
    "### Best Practices\n",
    "- Perform expensive operations asynchronously in background\n",
    "- Persist compaction results to avoid repeated computation\n",
    "- Track which events are included in summary to prevent redundant LLM sends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Considerations\n",
    "\n",
    "### Sessions\n",
    "\n",
    "**Security & Privacy:**\n",
    "- Strict Isolation: One user can never access another's session (ACLs)\n",
    "- PII Redaction: Redact before writing to storage (use Model Armor)\n",
    "- Authentication: Every request must be authenticated/authorized\n",
    "\n",
    "**Data Integrity:**\n",
    "- Time-to-Live (TTL): Auto-delete inactive sessions\n",
    "- Data Retention Policy: Define how long sessions kept before archival\n",
    "- Deterministic Order: Guarantee operations appended chronologically\n",
    "\n",
    "**Performance:**\n",
    "- Fast Read/Write: Session data on hot path of every interaction\n",
    "- Minimize Transfer Size: Filter/compact history before sending\n",
    "- Network Latency: Stateless runtimes retrieve from central database\n",
    "\n",
    "### Memory\n",
    "\n",
    "**Architecture:**\n",
    "- Decoupled Service: Memory processing separate from main application\n",
    "- Non-blocking API Calls: Agent pushes data, service acknowledges immediately\n",
    "- Internal Queue: Service manages background processing\n",
    "- Persistent Storage: Dedicated durable database for memories\n",
    "\n",
    "**Scalability:**\n",
    "- Race Condition Prevention: Transactional operations or optimistic locking\n",
    "- Message Queue: Buffer high-volume events\n",
    "- Failure Handling: Retry with exponential backoff, dead-letter queue\n",
    "- Multi-region: Built-in replication for global applications\n",
    "\n",
    "**Security:**\n",
    "- Data Isolation: Strict per-user/tenant memory separation with ACLs\n",
    "- User Control: Opt-out of memory generation, request data deletion\n",
    "- PII Redaction: Sanitize before committing to memory\n",
    "- Memory Poisoning Prevention: Validate and sanitize via Model Armor\n",
    "- Exfiltration Risk: Anonymize shared memories (e.g., procedural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "### Memory Quality\n",
    "- **Precision:** Of all memories created, percentage that are accurate/relevant\n",
    "- **Recall:** Of all relevant facts, percentage captured\n",
    "- **F1 Score:** Harmonic mean of precision and recall\n",
    "\n",
    "### Retrieval Performance\n",
    "- **Recall@K:** Is correct memory found within top K retrieved results?\n",
    "- **Latency:** Retrieval must execute within strict budget (e.g., <200ms)\n",
    "\n",
    "### Task Success\n",
    "- **Method:** LLM judge compares agent's output to golden answer\n",
    "- **Measures:** How well memory contributed to final outcome\n",
    "\n",
    "### Continuous Improvement\n",
    "1. Establish baseline metrics\n",
    "2. Analyze failures systematically\n",
    "3. Tune system (prompts, algorithms)\n",
    "4. Re-evaluate to measure impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Truncation (ADK)\n",
    "\n",
    "**Description:** Keep last N turns without modifying stored session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.plugins.context_filter_plugin import ContextFilterPlugin\n",
    "\n",
    "app = App(\n",
    "    name='hello_world_app',\n",
    "    root_agent=agent,\n",
    "    plugins=[\n",
    "        ContextFilterPlugin(num_invocations_to_keep=10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Compaction (ADK)\n",
    "\n",
    "**Description:** LLM-based summarization after N turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.apps.app import EventsCompactionConfig\n",
    "\n",
    "app = App(\n",
    "    name='hello_world_app',\n",
    "    root_agent=agent,\n",
    "    events_compaction_config=EventsCompactionConfig(\n",
    "        compaction_interval=5,\n",
    "        overlap_size=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Generation (Multimodal)\n",
    "\n",
    "**Description:** Generate memories from text and multimodal input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.agent_engines.memories.generate(\n",
    "    name=agent_engine_name,\n",
    "    direct_contents_source={\n",
    "        'events': [{\n",
    "            'content': types.Content(\n",
    "                role='user',\n",
    "                parts=[\n",
    "                    types.Part.from_text('Context about input'),\n",
    "                    types.Part.from_bytes(data=BYTES, mime_type=MIME),\n",
    "                    types.Part.from_uri(file_uri='path', mime_type=MIME)\n",
    "                ]\n",
    "            )\n",
    "        }]\n",
    "    },\n",
    "    scope={'user_id': user_id}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Retrieval (Proactive)\n",
    "\n",
    "**Description:** Automatically retrieve memories at start of every turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools.preload_memory_tool import PreloadMemoryTool\n",
    "\n",
    "agent = LlmAgent(\n",
    "    tools=[PreloadMemoryTool()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Retrieval (Reactive)\n",
    "\n",
    "**Description:** Agent decides when to retrieve memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(query: str, tool_context: ToolContext):\n",
    "    '''Retrieves memories. Available info: user preferences, favorites...'''\n",
    "    response = tool_context.search_memory(query)\n",
    "    return response.memories\n",
    "\n",
    "agent = LlmAgent(\n",
    "    tools=[load_memory]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory in System Instructions\n",
    "\n",
    "**Description:** Dynamically add memories to system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "template = Template('''\n",
    "{{ system_instructions }}\n",
    "<MEMORIES>\n",
    "{% for memory in data %}* {{ memory.memory.fact }}{% endfor %}\n",
    "</MEMORIES>\n",
    "''')\n",
    "\n",
    "prompt = template.render(\n",
    "    system_instructions=instructions,\n",
    "    data=retrieved_memories\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Build a Session-Based Shopping Assistant with Compaction\n",
    "\n",
    "**Objective:** Create an agent that maintains shopping cart state within a session and implements conversation compaction\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Estimated Time:** 45-60 minutes\n",
    "\n",
    "### Requirements\n",
    "- Build an agent that helps users shop for products\n",
    "- Implement session state to track shopping cart items\n",
    "- Add products to cart, remove products, view cart\n",
    "- Implement token-based or turn-based session compaction\n",
    "- Test with a long conversation (10+ turns)\n",
    "- Verify compaction preserves cart state while reducing history\n",
    "\n",
    "### Implementation Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define Cart Management Tools\n",
    "- Create add_to_cart(product_name, quantity) function\n",
    "- Create remove_from_cart(product_name) function\n",
    "- Create view_cart() function\n",
    "- All functions should accept tool_context parameter\n",
    "- Access session state via tool_context to read/write cart data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_cart(product_name: str, quantity: int, tool_context: ToolContext) -> dict:\n",
    "    '''Adds product to shopping cart'''\n",
    "    # Access session state\n",
    "    cart = tool_context._invocation_context.state.get('cart', [])\n",
    "    \n",
    "    # Add product\n",
    "    cart.append({'product': product_name, 'quantity': quantity})\n",
    "    \n",
    "    # Update state\n",
    "    tool_context._invocation_context.state['cart'] = cart\n",
    "    \n",
    "    return {'status': 'success', 'cart': cart}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create Shopping Agent\n",
    "- Initialize LlmAgent with Gemini model\n",
    "- Add cart management functions to tools list\n",
    "- Write clear instructions for handling shopping requests\n",
    "- Include guidance on when to use each tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Configure Session with Compaction\n",
    "- Wrap agent in App with resumability enabled\n",
    "- Add ContextFilterPlugin to keep last N turns (e.g., 5)\n",
    "- OR configure EventsCompactionConfig for summarization\n",
    "- Create Runner with session_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = App(\n",
    "    name='shopping_assistant',\n",
    "    root_agent=shopping_agent,\n",
    "    resumability_config=ResumabilityConfig(is_resumable=True),\n",
    "    plugins=[\n",
    "        ContextFilterPlugin(num_invocations_to_keep=5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Test Long Conversation\n",
    "- Generate session_id for conversation\n",
    "- Add 5+ products to cart in separate turns\n",
    "- Remove some products\n",
    "- View cart multiple times\n",
    "- Ask questions about products\n",
    "- Verify cart state persists across all turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Verify Compaction\n",
    "- Inspect session history after conversation\n",
    "- Confirm older events are compacted/summarized\n",
    "- Verify cart state remains accurate\n",
    "- Test that agent can still access cart correctly\n",
    "\n",
    "### Validation Criteria\n",
    "- Cart state persists across entire conversation\n",
    "- Session history shows compaction after threshold\n",
    "- Agent correctly references cart contents after compaction\n",
    "- No loss of critical cart data\n",
    "- Token count reduced compared to full history\n",
    "\n",
    "### Bonus Challenges\n",
    "- Implement cart total calculation tool\n",
    "- Add product search with mock inventory\n",
    "- Implement checkout process with confirmation\n",
    "- Add session timeout handling\n",
    "- Persist cart to external storage for recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Build a Memory-Enabled Personal Assistant with Custom Topics\n",
    "\n",
    "**Objective:** Create an agent that generates, stores, and retrieves personalized memories using custom memory topics\n",
    "\n",
    "**Difficulty:** Advanced\n",
    "\n",
    "**Estimated Time:** 60-90 minutes\n",
    "\n",
    "### Requirements\n",
    "- Set up Agent Engine Memory Bank or equivalent memory service\n",
    "- Define custom memory topics relevant to personal assistance\n",
    "- Implement memory generation from conversations\n",
    "- Build memory retrieval (proactive or reactive)\n",
    "- Test personalization across multiple sessions\n",
    "- Implement memory consolidation to handle updates\n",
    "\n",
    "### Implementation Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Setup Memory Bank\n",
    "- Create Agent Engine in Google Cloud Vertex AI\n",
    "- Configure memory_bank_config with custom topics\n",
    "- Define custom topics: preferences, schedule, relationships, projects\n",
    "- Provide few-shot examples for each topic type\n",
    "- Initialize VertexAiMemoryBankService in ADK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_bank_config = {\n",
    "    'customization_configs': [{\n",
    "        'memory_topics': [\n",
    "            {'custom_memory_topic': {\n",
    "                'label': 'user_preferences',\n",
    "                'description': 'User likes, dislikes, favorites'\n",
    "            }},\n",
    "            {'custom_memory_topic': {\n",
    "                'label': 'user_schedule',\n",
    "                'description': 'Meetings, appointments, availability'\n",
    "            }}\n",
    "        ],\n",
    "        'generate_memories_examples': {\n",
    "            'conversationSource': {'events': [...]},\n",
    "            'generatedMemories': [{'fact': '...'}]\n",
    "        }\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create Memory Generation Tool\n",
    "- Define generate_memories(tool_context) function\n",
    "- Extract session from tool_context\n",
    "- Call memory_service.add_session_to_memory(session)\n",
    "- Set wait_for_completion=False for background processing\n",
    "- Return success status to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_memories(tool_context: ToolContext):\n",
    "    '''Saves important info about the user for future conversations'''\n",
    "    tool_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        tool_context._invocation_context.session\n",
    "    )\n",
    "    return {'status': 'memory_generation_triggered'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create Memory Retrieval Strategy\n",
    "- OPTION A: Use PreloadMemoryTool for automatic retrieval\n",
    "- OPTION B: Create custom load_memory(query) tool\n",
    "- Tool should search memories by semantic similarity\n",
    "- Return formatted memory facts to agent\n",
    "- Document available memory types in tool description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(query: str, tool_context: ToolContext):\n",
    "    '''Retrieves what you know about the user. Topics: preferences, schedule, relationships, projects'''\n",
    "    response = tool_context.search_memory(query)\n",
    "    return [{'fact': m.memory.fact} for m in response.memories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Build Personal Assistant Agent\n",
    "- Create LlmAgent with both memory tools\n",
    "- Write instructions to use memories for personalization\n",
    "- Include guidance on when to generate new memories\n",
    "- Add instructions for when to retrieve memories\n",
    "- Configure Runner with memory_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(\n",
    "    app=app,\n",
    "    session_service=session_service,\n",
    "    memory_service=VertexAiMemoryBankService(\n",
    "        agent_engine_id=AGENT_ENGINE_ID,\n",
    "        project=PROJECT,\n",
    "        location=LOCATION\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Test Memory Lifecycle\n",
    "- SESSION 1: User shares preferences (favorite food, meeting time)\n",
    "- Trigger memory generation at end of session\n",
    "- Wait for background generation to complete\n",
    "- SESSION 2: Ask agent about user preferences\n",
    "- Verify agent retrieves and uses correct memories\n",
    "- SESSION 3: User updates preference (changes favorite food)\n",
    "- Generate memories again\n",
    "- Verify memory consolidation updated preference\n",
    "\n",
    "#### Step 6: Test Cross-Session Personalization\n",
    "- Create new session with same user_id\n",
    "- Ask agent to make recommendation\n",
    "- Verify agent uses memories from previous sessions\n",
    "- Test that agent doesn't hallucinate - only uses stored memories\n",
    "\n",
    "### Custom Memory Topics\n",
    "\n",
    "**Example Topics:**\n",
    "- **user_preferences:** User's likes, dislikes, favorites, and personal preferences\n",
    "- **user_schedule:** Recurring meetings, appointments, availability patterns, time zones\n",
    "- **user_relationships:** Important people, family members, colleagues, and their details\n",
    "- **ongoing_projects:** Current work projects, goals, deadlines, and progress\n",
    "\n",
    "**Few-Shot Example:**\n",
    "- Conversation: [{'role': 'model', 'text': \"What's your favorite cuisine?\"}, {'role': 'user', 'text': 'I love Italian food, especially pasta carbonara'}]\n",
    "- Expected Memories: [{'fact': 'The user's favorite cuisine is Italian.'}, {'fact': 'The user especially loves pasta carbonara.'}]\n",
    "\n",
    "### Validation Criteria\n",
    "- Memories generated from first conversation\n",
    "- Memories successfully retrieved in subsequent sessions\n",
    "- Agent personalizes responses based on memories\n",
    "- Memory updates correctly handled via consolidation\n",
    "- No memory leakage between different users\n",
    "- Background memory generation doesn't block user experience\n",
    "\n",
    "### Bonus Challenges\n",
    "- Implement procedural memories for agent's successful strategies\n",
    "- Add memory confidence scoring based on source type\n",
    "- Build memory provenance tracking\n",
    "- Implement memory pruning for stale information\n",
    "- Create memory visualization dashboard\n",
    "- Add support for multimodal memory sources (images, audio)\n",
    "- Implement memory-based proactive suggestions\n",
    "\n",
    "### Testing Scenarios\n",
    "\n",
    "| Scenario          | Session 1 Description                                      | Session 2 Description                                      | Session 3 Description                                      |\n",
    "|-------------------|------------------------------------------------------------|------------------------------------------------------------|------------------------------------------------------------|\n",
    "| **Preference Learning** | User mentions they're vegetarian and prefer morning meetings | Agent suggests restaurant - should recommend vegetarian options | Agent schedules meeting - should prefer morning times |\n",
    "| **Memory Update** | User says favorite color is blue                           | User says they changed their mind, favorite is green now   | Agent should remember green, not blue                      |\n",
    "| **Relationship Context** | User mentions sister Sarah lives in Boston, birthday Nov 15 | Mid-November - agent should proactively mention Sarah's birthday | Planning Boston trip - agent should suggest visiting Sarah |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### Documentation\n",
    "- [Agent Engine Sessions](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/sessions/overview)\n",
    "- [Agent Engine Memory Bank](https://cloud.google.com/agent-builder/agent-engine/memory-bank/set-up)\n",
    "- [ADK Memory Guide](https://google.github.io/adk-docs/memory/)\n",
    "- [ADK Callbacks](https://google.github.io/adk-docs/callbacks/)\n",
    "- [Model Context Protocol](https://spec.modelcontextprotocol.io/)\n",
    "- [Agent-to-Agent Protocol](https://agent2agent.info/docs/concepts/message/)\n",
    "\n",
    "### Papers\n",
    "- [In-Context Learning](https://arxiv.org/abs/2301.00234)\n",
    "- [Long Context Limitations](https://ai.google.dev/gemini-api/docs/long-context)\n",
    "- [Memory Systems](https://huggingface.co/blog/Kseniase/memory)\n",
    "- [Atomic Facts](https://arxiv.org/pdf/2412.15266)\n",
    "- [Memory Poisoning](https://arxiv.org/pdf/2503.03704)\n",
    "- [RLHF on Google Cloud](https://cloud.google.com/blog/products/ai-machine-learning/rlhf-on-google-cloud)\n",
    "\n",
    "### Videos\n",
    "- [ADK Runtime Deep Dive](https://www.youtube.com/watch?v=44C8u0CDtSo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### Session Management\n",
    "- Always use persistent storage in production (never in-memory for prod)\n",
    "- Implement strict ACLs for session isolation between users\n",
    "- Redact PII before persisting session data\n",
    "- Set appropriate TTL policies for inactive sessions\n",
    "- Filter or compact history before sending to agent\n",
    "- Use deterministic ordering for event appending\n",
    "- Monitor session read/write latency closely\n",
    "- Implement proper error handling for session failures\n",
    "\n",
    "### Memory Generation\n",
    "- Run memory generation asynchronously in background\n",
    "- Never block user response waiting for memory generation\n",
    "- Define clear, specific custom memory topics\n",
    "- Provide few-shot examples for complex topics\n",
    "- Trigger generation at appropriate cadence (not every turn)\n",
    "- Implement proper error handling and retry logic\n",
    "- Track memory provenance for trustworthiness\n",
    "- Regularly prune stale or low-confidence memories\n",
    "\n",
    "### Memory Retrieval\n",
    "- Combine relevance, recency, and importance in scoring\n",
    "- Don't rely solely on semantic similarity\n",
    "- Cache expensive retrieval operations when possible\n",
    "- Set strict latency budgets for hot-path retrieval\n",
    "- Consider memory-as-a-tool for efficiency\n",
    "- Document available memory types in tool descriptions\n",
    "- Test retrieval with diverse query types\n",
    "- Monitor retrieval performance metrics continuously\n",
    "\n",
    "### Memory Security\n",
    "- Enforce strict per-user memory isolation with ACLs\n",
    "- Sanitize and validate before persisting memories\n",
    "- Use Model Armor or similar for PII redaction\n",
    "- Provide user controls for opt-out and deletion\n",
    "- Anonymize shared memories (procedural, application-level)\n",
    "- Audit memory access patterns regularly\n",
    "- Implement memory poisoning defenses\n",
    "- Handle data deletion requests properly (derived data)\n",
    "\n",
    "### Context Engineering\n",
    "- Treat context construction as a mise en place process\n",
    "- Dynamically select only relevant information for context\n",
    "- Balance information completeness vs. token efficiency\n",
    "- Use in-context learning with relevant few-shot examples\n",
    "- Implement context compaction strategies proactively\n",
    "- Monitor context window usage and costs\n",
    "- Test with varying context sizes and compositions\n",
    "- Profile hot-path vs. background operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "| Pitfall                                      | Solution                                                                 |\n",
    "|---------------------------------------------|--------------------------------------------------------------------------|\n",
    "| **Blocking user experience with memory generation** | Always use wait_for_completion=False and run generation in background    |\n",
    "| **Processing same events multiple times**   | Track which events already contributed to memories, avoid redundant processing |\n",
    "| **Relying only on semantic similarity for retrieval** | Blend relevance, recency, and importance scores                         |\n",
    "| **Not handling memory conflicts**           | Implement consolidation with clear conflict resolution strategy          |\n",
    "| **Storing too much in session state**       | Keep only temporary working memory in state, move facts to long-term memory |\n",
    "| **Not compacting long conversations**       | Implement token-based or turn-based compaction early                    |\n",
    "| **Sharing memories across users accidentally** | Always scope memories by user_id, test isolation rigorously              |\n",
    "| **Treating memories as ground truth**       | Track provenance, confidence scores, validate against authoritative sources |\n",
    "| **Not pruning stale memories**              | Implement time-based decay and periodic pruning                          |\n",
    "| **Injecting memories without context**      | Add preambles explaining what the memories represent                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Session Issues\n",
    "- **Symptom:** Session data not persisting across calls\n",
    "- **Checks:**\n",
    "  - Verify persistent storage is configured (not InMemorySessionService)\n",
    "  - Confirm same session_id used across calls\n",
    "  - Check database connectivity and permissions\n",
    "  - Verify session isn't expired via TTL policy\n",
    "\n",
    "### Memory Generation Failures\n",
    "- **Symptom:** Memories not being created\n",
    "- **Checks:**\n",
    "  - Verify Agent Engine is properly configured\n",
    "  - Check custom topic definitions are clear\n",
    "  - Ensure conversation contains relevant information\n",
    "  - Review memory generation API response for errors\n",
    "  - Wait sufficient time for background processing\n",
    "  - Check IAM permissions for memory service\n",
    "\n",
    "### Memory Retrieval Empty\n",
    "- **Symptom:** No memories returned when expected\n",
    "- **Checks:**\n",
    "  - Verify memories were actually generated (check database)\n",
    "  - Confirm user_id matches between generation and retrieval\n",
    "  - Test with broader/different queries\n",
    "  - Check if memories were pruned or expired\n",
    "  - Verify memory scope (user vs session vs application)\n",
    "  - Review retrieval query is semantically related\n",
    "\n",
    "### High Latency\n",
    "- **Symptom:** Agent responses are slow\n",
    "- **Checks:**\n",
    "  - Profile where time is spent (context fetch, LLM, memory)\n",
    "  - Implement session history compaction\n",
    "  - Use proactive memory retrieval sparingly\n",
    "  - Cache frequently retrieved memories\n",
    "  - Optimize memory retrieval query complexity\n",
    "  - Check database query performance\n",
    "  - Reduce number of tools/memories in context\n",
    "\n",
    "### Context Window Overflow\n",
    "- **Symptom:** Context window exceeded errors\n",
    "- **Checks:**\n",
    "  - Implement ContextFilterPlugin or EventsCompactionConfig\n",
    "  - Reduce number of turns kept in history\n",
    "  - Summarize older conversation sections\n",
    "  - Limit number of memories retrieved\n",
    "  - Use recursive summarization for long sessions\n",
    "  - Monitor token counts proactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics\n",
    "\n",
    "### Procedural Memory\n",
    "**Definition:** Memories that capture 'how to' perform tasks, not just 'what' facts\n",
    "\n",
    "**Lifecycle Differences:**\n",
    "- Extraction: Requires specialized prompts to distill reusable strategies\n",
    "- Consolidation: Curates workflows, patches flawed steps, integrates best practices\n",
    "- Retrieval: Finds plans that guide task execution, not just answer questions\n",
    "\n",
    "**Comparison to Fine-Tuning:**\n",
    "- **Fine-Tuning:** Slow, offline training process altering model weights\n",
    "- **Procedural Memory:** Fast, online adaptation via in-context learning\n",
    "\n",
    "**Use Cases:**\n",
    "- Agent builds playbook of successful problem-solving strategies\n",
    "- Learning optimal tool call sequences\n",
    "- Capturing domain-specific workflows\n",
    "- Self-improvement through experience\n",
    "\n",
    "### Multimodal Memory\n",
    "\n",
    "**From Multimodal Source:**\n",
    "- Description: Process images/audio/video to create textual memories\n",
    "- Example: Transcribe voice memo, extract memory: 'User frustrated about shipping delay'\n",
    "- Current Standard: Most memory managers use this approach\n",
    "\n",
    "**With Multimodal Content:**\n",
    "- Description: Store non-textual media directly in memory\n",
    "- Example: User uploads logo image, agent stores actual image file\n",
    "- Challenges: Requires specialized models and infrastructure\n",
    "- Current Status: Advanced implementation, less common\n",
    "\n",
    "### Memory Consolidation Strategies\n",
    "- **Deduplication:** Merge redundant memories mentioning same fact differently\n",
    "- **Conflict Resolution:** Handle contradictory information with trust hierarchy\n",
    "- **Evolution:** Update simple facts to more nuanced versions\n",
    "- **Forgetting:** Prune stale, low-confidence, or irrelevant memories\n",
    "- **Confidence Scoring:** Dynamic confidence based on corroboration and age\n",
    "\n",
    "### Hybrid Architectures\n",
    "\n",
    "**RAG + Memory:**\n",
    "- Pattern: RAG for world facts, Memory for user knowledge\n",
    "- Analogy: RAG is research librarian, Memory is personal assistant\n",
    "- Implementation: Both retrieval systems work in parallel, context merges results\n",
    "\n",
    "**Vector + Graph:**\n",
    "- Pattern: Vector DB for semantic search, Knowledge Graph for relationships\n",
    "- Advantage: Structured reasoning AND conceptual similarity\n",
    "- Use Case: Complex queries requiring both entity relationships and semantic matching\n",
    "\n",
    "### Multi-Agent Memory Sharing\n",
    "- **Challenge:** Different frameworks have incompatible session schemas\n",
    "- **Solution:** Memory as universal translation layer\n",
    "- **Benefit:** Heterogeneous agents share common cognitive resource\n",
    "- **Implementation:** All agents connect to same memory service\n",
    "- **A2A Protocol:** Agent-to-Agent communication for message passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Examples\n",
    "\n",
    "### Customer Support\n",
    "- **Scenario:** Multi-tier support system with escalation\n",
    "- **Session Strategy:** Shared history across tier agents\n",
    "- **Memory Strategy:** User-level memories for past issues and preferences\n",
    "- **Key Features:**\n",
    "  - Track customer history across all interactions\n",
    "  - Remember previous issues and resolutions\n",
    "  - Personalize support based on customer preferences\n",
    "  - Generate procedural memories for successful resolution patterns\n",
    "\n",
    "### Personal Assistant\n",
    "- **Scenario:** Scheduling, reminders, and personalization\n",
    "- **Session Strategy:** Separate sessions per conversation\n",
    "- **Memory Strategy:** Rich user profile with preferences, schedule, relationships\n",
    "- **Key Features:**\n",
    "  - Remember user preferences and habits\n",
    "  - Track ongoing projects and goals\n",
    "  - Maintain relationships context\n",
    "  - Proactive suggestions based on patterns\n",
    "\n",
    "### Educational Tutor\n",
    "- **Scenario:** Personalized learning with progress tracking\n",
    "- **Session Strategy:** Session per learning session\n",
    "- **Memory Strategy:** Student profile, knowledge gaps, learning style\n",
    "- **Key Features:**\n",
    "  - Track student's knowledge level per topic\n",
    "  - Remember learning style preferences\n",
    "  - Adapt difficulty based on past performance\n",
    "  - Generate procedural memories for effective teaching strategies\n",
    "\n",
    "### Sales Assistant\n",
    "- **Scenario:** Lead qualification and relationship management\n",
    "- **Session Strategy:** Session per sales interaction\n",
    "- **Memory Strategy:** Client preferences, business needs, interaction history\n",
    "- **Key Features:**\n",
    "  - Remember client's business context and pain points\n",
    "  - Track previous conversations and proposals\n",
    "  - Personalize pitch based on known preferences\n",
    "  - Consolidate information across multiple touchpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz Questions\n",
    "\n",
    "1. **Question:** What is the key difference between Context Engineering and Prompt Engineering?\n",
    "   - Options:\n",
    "     - Context Engineering is only for production systems\n",
    "     - Context Engineering dynamically constructs state-aware prompts, while Prompt Engineering focuses on static system instructions\n",
    "     - Prompt Engineering is more advanced\n",
    "     - They are the same thing\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** Context Engineering evolved from Prompt Engineering to address the entire payload, dynamically constructing prompts based on user, history, and external data\n",
    "\n",
    "2. **Question:** What is the primary purpose of a Session in agent systems?\n",
    "   - Options:\n",
    "     - Long-term storage of user preferences\n",
    "     - Container for a single conversation with chronological history and working memory\n",
    "     - External API integration\n",
    "     - Model fine-tuning data\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** A Session encapsulates the immediate dialogue history and working memory for a single, continuous conversation tied to a specific user\n",
    "\n",
    "3. **Question:** How does Memory differ from RAG?\n",
    "   - Options:\n",
    "     - Memory is for user-specific dynamic context, RAG is for shared factual knowledge\n",
    "     - RAG is faster than Memory\n",
    "     - Memory can't handle multimodal data\n",
    "     - RAG is always more accurate\n",
    "   - **Correct:** 0\n",
    "   - **Explanation:** Memory creates personalized, stateful experiences from user dialogue, while RAG injects external, factual knowledge from static knowledge bases\n",
    "\n",
    "4. **Question:** What are the two main stages of memory generation?\n",
    "   - Options:\n",
    "     - Reading and Writing\n",
    "     - Extraction and Consolidation\n",
    "     - Indexing and Querying\n",
    "     - Training and Inference\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** Memory generation involves Extraction (filtering meaningful content) and Consolidation (merging, updating, or deleting memories to maintain coherence)\n",
    "\n",
    "5. **Question:** Why should memory generation run asynchronously?\n",
    "   - Options:\n",
    "     - It's cheaper\n",
    "     - It's more accurate\n",
    "     - To avoid blocking user response with expensive LLM calls and database writes\n",
    "     - It's a requirement of all memory systems\n",
    "   - **Correct:** 2\n",
    "   - **Explanation:** Memory generation is expensive and should run in the background after the agent responds to keep the user experience fast and responsive\n",
    "\n",
    "6. **Question:** What is memory consolidation?\n",
    "   - Options:\n",
    "     - Compressing memories to save storage space\n",
    "     - Self-editing process that merges, updates, or deletes memories to maintain coherent knowledge\n",
    "     - Moving memories to cold storage\n",
    "     - Converting text memories to embeddings\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** Consolidation is the sophisticated stage where new memories are integrated with existing ones through UPDATE, CREATE, or DELETE operations\n",
    "\n",
    "7. **Question:** What is the recommended approach for handling long conversations?\n",
    "   - Options:\n",
    "     - Always send full history to maintain perfect context\n",
    "     - Implement compaction strategies like summarization or truncation\n",
    "     - Restart the conversation when it gets too long\n",
    "     - Increase the context window indefinitely\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** Compaction strategies (token-based truncation, recursive summarization) reduce token count while preserving vital information\n",
    "\n",
    "8. **Question:** What is memory provenance and why does it matter?\n",
    "   - Options:\n",
    "     - The location where memory is stored\n",
    "     - Detailed record of memory's origin and history used to assess trustworthiness\n",
    "     - The time when memory was created\n",
    "     - The format of the memory data\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** Provenance tracks memory sources and history, enabling trust assessment, conflict resolution, and proper handling of derived data\n",
    "\n",
    "9. **Question:** What's the difference between proactive and reactive memory retrieval?\n",
    "   - Options:\n",
    "     - Proactive is faster\n",
    "     - Proactive auto-loads at every turn, reactive lets agent decide when to retrieve\n",
    "     - Reactive is more accurate\n",
    "     - They are the same\n",
    "   - **Correct:** 1\n",
    "   - **Explanation:** Proactive retrieval automatically loads memories every turn; reactive (memory-as-a-tool) lets the agent decide when retrieval is needed\n",
    "\n",
    "10. **Question:** Why can't different agent frameworks directly share sessions?\n",
    "    - Options:\n",
    "      - Security restrictions\n",
    "      - Different frameworks use incompatible internal schemas for storing session events\n",
    "      - Sessions can only be stored locally\n",
    "      - It's a technical limitation of LLMs\n",
    "    - **Correct:** 1\n",
    "    - **Explanation:** Each framework's session storage couples the database schema to its internal objects, making sessions framework-specific and non-portable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "| Term                  | Definition                                                                 |\n",
    "|-----------------------|----------------------------------------------------------------------------|\n",
    "| **context_engineering** | The process of dynamically assembling and managing information within an LLM's context window |\n",
    "| **session**           | Container for single conversation with chronological history and working memory |\n",
    "| **memory**            | Long-term persistence mechanism capturing key information across multiple sessions |\n",
    "| **event**             | Building block of conversation (user input, agent response, tool call, tool output) |\n",
    "| **state**             | Structured working memory or scratchpad with temporary data |\n",
    "| **extraction**        | Process of distilling meaningful information from source data into memories |\n",
    "| **consolidation**     | Self-editing process comparing new information with existing memories to maintain coherence |\n",
    "| **provenance**        | Detailed record of memory's origin and history for trustworthiness assessment |\n",
    "| **compaction**        | Strategy to reduce conversation history size while preserving key information |\n",
    "| **declarative_memory**| Knowledge of facts, figures, and events (knowing what) |\n",
    "| **procedural_memory** | Knowledge of skills and workflows (knowing how) |\n",
    "| **memory_as_a_tool**  | Pattern where agent decides when to generate or retrieve memories |\n",
    "| **context_window**    | Maximum amount of text an LLM can process in a single API call |\n",
    "| **token**             | Basic unit of text processing for LLMs, roughly 3/4 of a word |\n",
    "| **embedding**         | Vector representation of text enabling semantic similarity search |\n",
    "| **vector_database**   | Database storing embeddings for fast similarity search |\n",
    "| **knowledge_graph**   | Network of entities and relationships for structured reasoning |\n",
    "| **rag**               | Retrieval-Augmented Generation - injecting external knowledge into context |\n",
    "| **llm**               | Large Language Model - AI model trained on vast text data |\n",
    "| **a2a**               | Agent-to-Agent protocol for message passing between agents |\n",
    "| **mcp**               | Model Context Protocol - standard for agent tool integration |\n",
    "| **acl**               | Access Control List - defines who can access what resources |\n",
    "| **pii**               | Personally Identifiable Information requiring protection |\n",
    "| **ttl**               | Time-To-Live - how long data persists before automatic deletion |\n",
    "| **hot_path**          | Critical code path that must execute quickly (user-facing) |\n",
    "| **cold_storage**      | Low-cost storage for infrequently accessed data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "- Context Engineering is the foundation of stateful AI - dynamically assembling information for each LLM call\n",
    "- Sessions manage immediate conversation state; Memory provides long-term persistence\n",
    "- Memory generation is an LLM-driven ETL pipeline: Ingestion  Extraction  Consolidation  Storage\n",
    "- Always run memory generation asynchronously to avoid blocking user experience\n",
    "- Memory differs from RAG: Memory is personalized user context, RAG is shared factual knowledge\n",
    "- Implement compaction strategies early to manage long conversations\n",
    "- Track memory provenance for trustworthiness and conflict resolution\n",
    "- Use hybrid retrieval: blend relevance, recency, and importance scores\n",
    "- Enforce strict isolation and security: ACLs, PII redaction, user controls\n",
    "- Memory enables true personalization and agent self-improvement\n",
    "\n",
    "### Production Checklist\n",
    "-  Use persistent storage for sessions (not in-memory)\n",
    "-  Implement strict per-user isolation with ACLs\n",
    "-  Redact PII before persisting data\n",
    "-  Configure appropriate TTL policies\n",
    "-  Implement session compaction strategy\n",
    "-  Run memory generation asynchronously\n",
    "-  Define clear custom memory topics\n",
    "-  Track memory provenance and confidence\n",
    "-  Implement memory pruning strategy\n",
    "-  Monitor performance metrics (latency, token usage)\n",
    "-  Test memory isolation rigorously\n",
    "-  Provide user controls for data deletion\n",
    "-  Set up error handling and retry logic\n",
    "-  Profile hot-path operations\n",
    "-  Implement comprehensive evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### After Completing Tasks\n",
    "- Experiment with different compaction strategies and measure impact\n",
    "- Build multi-user system and test memory isolation\n",
    "- Implement procedural memories for agent self-improvement\n",
    "- Create memory visualization and debugging tools\n",
    "- Test with multimodal memory sources (images, audio)\n",
    "- Build hybrid RAG + Memory architecture\n",
    "- Implement advanced retrieval with query rewriting and reranking\n",
    "- Deploy to production with monitoring and evaluation\n",
    "- Optimize for cost and latency at scale\n",
    "- Explore Agent-to-Agent communication patterns\n",
    "\n",
    "### Continue Learning\n",
    "- Day 4: Multi-agent orchestration patterns\n",
    "- Day 5: Production deployment and monitoring\n",
    "- Advanced: Fine-tuning vs. in-context learning\n",
    "- Advanced: Building custom memory managers\n",
    "- Advanced: Memory-augmented reasoning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "title": "Context Engineering: Sessions & Memory"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
